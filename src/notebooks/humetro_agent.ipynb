{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "sys.path.append('../..')\n",
        "_ = load_dotenv(find_dotenv())  # read local .env file\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import langchain\n",
        "from langchain.agents.agent_toolkits import create_conversational_retrieval_agent\n",
        "from langchain.agents import load_tools, initialize_agent, tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0, model='gpt-4o-mini', streaming=True)\n",
        "langchain.debug = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Tools\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ì—´ì°¨ ì‹œê°„í‘œ ì¡°íšŒ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_train_schedule(station_name: str = 'í•˜ë‹¨') -> str:\n",
        "    \"\"\"Returns today's train schedule of the given station name.\n",
        "    Output is formatted as CSV\"\"\"\n",
        "    return \"\"\"\n",
        "    ì‹œê°„,ë¶„,í–‰ì„ ì§€,\n",
        "    5, 4, ë…¸í¬,\n",
        "    5, 20, ë…¸í¬,\n",
        "    10, 20, ë…¸í¬,\n",
        "    20,40,ë…¸í¬,\n",
        "    23,40,ë…¸í¬,\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ì—­ê°„ ì´ë™ì‹œê°„ ì¡°íšŒ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_estimated_time(from_station: str = 'í•˜ë‹¨') -> str:\n",
        "    \"\"\"\n",
        "    Returns all estimated time from from_station.\n",
        "    \"\"\"\n",
        "    return '32ë¶„'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ì—­ê°„ êµ¬ê°„ ì¡°íšŒ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def get_distance_type(from_station: str = 'í•˜ë‹¨') -> str:\n",
        "    \"\"\"\n",
        "    Returns all distance type from_station\n",
        "    \"\"\"\n",
        "    return '2êµ¬ê°„'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "from duckduckgo_search import ddg\n",
        "\n",
        "\n",
        "@tool\n",
        "def ddg_search(query: str) -> str:\n",
        "    \"\"\"\n",
        "    When there is no relavant tools, use this tool to search online and retrieve relavant information\n",
        "    \"\"\"\n",
        "    query = \"site:http://www.humetro.busan.kr/homepage/default/ \" + query\n",
        "    searches = ddg(query, max_results=10)\n",
        "    links = set()\n",
        "    for search in searches:\n",
        "        link = search['href']\n",
        "        if \"www.humetro.busan.kr/default/main.do\" in link:\n",
        "            continue\n",
        "        if 'login.do' in link:\n",
        "            continue\n",
        "        links.add(link)\n",
        "    return 'ìš”ê¸ˆì€ ëª¨ë‘ ì‚¼ì²œì›ì…ë‹ˆë‹¤. ì–´ë¦°ì´ êµí†µì¹´ë“œë¥¼ ì‚´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—­ì‚¬ë‚´ì— í¸ì˜ì ì´ ìˆìŠµë‹ˆë‹¤.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ë²¡í„° ìŠ¤í† ì–´\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import NotionDirectoryLoader\n",
        "loader = NotionDirectoryLoader(\"./notion_db\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
        "splitter = MarkdownHeaderTextSplitter(\n",
        "    headers_to_split_on=[\n",
        "        (\"#\", \"Header 1\"),\n",
        "        (\"##\", \"Header 2\"),\n",
        "        (\"###\", \"Header 3\"),\n",
        "    ]\n",
        ")\n",
        "splitted_docs = splitter.split_text(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "chunk_size = 2000\n",
        "chunk_overlap = 200\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap)\n",
        "splits = text_splitter.split_documents(splitted_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm -rf ./chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "vector_db = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    persist_directory='chroma'\n",
        ")\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='ê¸°ë³¸ê°€ê²© ë° ì‚¬ì´ì¦ˆ  \\n| êµ¬ë¶„ | ì†Œ | ì¤‘ | ëŒ€ | íŠ¹ëŒ€ |\\n| --- | --- | --- | --- | --- |\\n| ê¸°ë³¸ê°€ê²©(ì›) | 2,000 | 3,000 | 4,000 | 5,000 |\\n| êµ¬í˜• ì‚¬ì´ì¦ˆ(cm) | 30Ã—42Ã—55 | 40Ã—42Ã—55 | 50Ã—42Ã—55 | 60Ã—42Ã—55 |\\n| ì‹ í˜• ì‚¬ì´ì¦ˆ(cm) | 37Ã—27Ã—55 | 37Ã—37Ã—55 | 37Ã—57Ã—55 | 37Ã—87Ã—55 |  \\n**ì¶”ê°€ìš”ê¸ˆ**  \\n- êµ¬í˜•: í˜„ê¸ˆë§Œ ê°€ëŠ¥\\n- ì‹ í˜•: í˜„ê¸ˆÂ·ì¹´ë“œ ê°€ëŠ¥\\n- 1í˜¸ì„  ì‹ í˜• ë¬¼í’ˆë³´ê´€í•¨ ì„¤ì¹˜ ì—­ì‚¬ : ìê°ˆì¹˜, ë‚¨í¬, ë¶€ì‚°, ë²”ë‚´ê³¨, ì„œë©´, ì‹œì²­, ì—°ì‚°, ë™ë˜, ë¶€ì‚°ëŒ€\\n- ë‹¹ì¼ ìì •(24:00ì´í›„) ìš”ê¸ˆ(ì†Œ 2,000ì›/ ì¤‘ 3,000ì›/ ëŒ€ 5,000ì›)ì´ ì¶”ê°€ë˜ë©° ì¶”í›„ì— ë¬¼í’ˆì„ ì°¾ì„ ë•Œ ë‚©ë¶€\\n- ì˜ˆ) 23:50ë¶„ì— ì†Œí˜• ë¬¼í’ˆë³´ê´€í•¨ ì‚¬ìš© ì‹œ ê¸°ë³¸ 2,000ì›ì— 24:00ì‹œë¥¼ ê¸°í•˜ì—¬ 2,000ì›ì´ ì¶”ê°€ë˜ì–´ 4,000ì›ì´ ë©ë‹ˆë‹¤  \\n| êµ¬ë¶„ | ê¸°ë³¸ ìš”ê¸ˆ | ì¶”ê°€ ë°˜ë³µ ìš”ê¸ˆ1 (4ì‹œê°„ ì´í›„ 12ì‹œê°„ê¹Œì§€ 1ì‹œê°„ë§ˆë‹¤ ë°˜ë³µ ì¶”ê°€ ê³¼ê¸ˆ) | ì¶”ê°€ ë°˜ë³µ ìš”ê¸ˆ2 (12ì‹œê°„ ì´í›„ 12ì‹œê°„ë§ˆë‹¤ ë°˜ë³µ ì¶”ê°€ ê³¼ê¸ˆ) |\\n| --- | --- | --- | --- |\\n| ì†Œí˜• | 2,000 | +300 | +2,000 |\\n| ì¤‘í˜• | 3,000 | +400 | +3,000 |\\n| ëŒ€í˜• | 4,000 | +500 | +4,000 |\\n| íŠ¹ëŒ€í˜• | 5,000 | +600 |  |  \\n**ì—­ë³„ ë¬¼í’ˆë³´ê´€í•¨ í˜„í™©**  \\n| ì—­ëª… | ì†Œ | ì¤‘ | ëŒ€ | íŠ¹ëŒ€ |\\n| --- | --- | --- | --- | --- |\\n| ë‹¤ëŒ€í¬í•´ìˆ˜ìš•ì¥ | 10 | 8 | 4 |  |\\n| ë‹¤ëŒ€í¬í•­ | 10 | 8 | 2 |  |\\n| ë™ë§¤ | 10 | 8 | 2 |  |\\n| í•˜ë‹¨ | 10 | 16 | 4 |  |\\n| ê´´ì • | 10 | 8 | 4 |  |\\n| ë™ëŒ€ì‹  | 10 | 4 | 2 |  |\\n| í† ì„± | 10 | 8 | 4 |  |\\n| ìê°ˆì¹˜ | 34 | 42 | 4 | 27 |\\n| ë‚¨í¬ | 33 | 45 | 42 |  |\\n| ì¤‘ì•™ | 10 | 16 | 4 |  |\\n| ë¶€ì‚° | 18 | 52 | 6 | 36 |\\n| ì´ˆëŸ‰ | 10 | 8 | 4 |  |\\n| ë¶€ì‚°ì§„ | 10 | 8 | 4 |  |\\n| ë²”ì¼ | 10 | 16 | 4 |  |\\n| ë²”ë‚´ê³¨ | 6 | 8 | 4 |  |\\n| ì„œë©´(1) | 36 | 60 | 12 | 34 |\\n| ë¶€ì „ | 10 | 12 | 4 |  |\\n| ì–‘ì • | 10 | 8 | 2 |  |\\n| ì‹œì²­ | 6 | 10 | 3 |  |\\n| ì—°ì‚°(1) | 6 | 14 | 5 |  |\\n| ë™ë˜(1) | 9 | 14 | 6 |  |\\n| ëª…ë¥œ | 10 | 8 | 2 |  |\\n| ì˜¨ì²œì¥ | 10 | 8 | 4 |  |\\n| ë¶€ì‚°ëŒ€ | 12 | 26 | 9 |  |\\n| ì¥ì „ | 10 | 8 | 2 |  |\\n| ë‚¨ì‚° | 10 | 8 | 2 |  |\\n| ë…¸í¬ | 10 | 8 | 2 |  |\\n| ê³„ | 340 | 439 | 122 | 222 |  \\n1í˜¸ì„  ë¬¼í’ˆë³´ê´€í•¨ ìœ„íƒìš´ì˜ì—…ì²´: ìœ„ë“œë½ì¹´(051-440-2100)', metadata={'Header 1': 'STEPâ…  ì—­ë¬´ì¼ë°˜', 'Header 2': 'CHAPTER2 ê³ ê°ì„œë¹„ìŠ¤', 'Header 3': '6ê°• ë¬¼í’ˆë³´ê´€í•¨ ê´€ë ¨'}),\n",
              " Document(page_content='<aside>\\nğŸ’¡ ì¼íƒ€ì—­ë¬´ êµì¬ (ë¯¼ì›ì‘ëŒ€ë§Œ ë°œì·Œ), ì—­ë¬´ì‹¤ë¬´ êµì¬, SQI ì¡°ì‚¬ ì§ˆì˜ë‹µë³€, ê³ ê°ì„œë¹„ìŠ¤ ë¡œë“œë§µ(2022)  \\n</aside>', metadata={'Header 1': 'ìœ„í‚¤'}),\n",
              " Document(page_content='- í–‰ì‚¬ì¥ì†Œ : ë„ì‹œì² ë„ ì „ ì—­ì‚¬ ë‚´ ì‹œì„¤(ì†Œë°© ê´€ë ¨ì‹œì„¤, ì„ëŒ€ë§¤ì¥ ë“±) ë° ê³ ê°ì˜\\në™ì„ ì— ì§€ì¥ì„ ì£¼ì§€ ì•ŠëŠ” ë²”ìœ„ë‚´ì˜ ëª¨ë“  ì¥ì†Œ\\n- ìŠ¹ì¸ëŒ€ìƒ : ê³µê³µê¸°ê´€ ë° ë¹„ì˜ë¦¬ ë²•ì¸ë‹¨ì²´, í•™êµ, ìƒì—…ì„±ì´ ì—†ëŠ” ê°œì¸ ë“±\\n- ìŠ¹ì¸ë¶„ì•¼ : ê³µì—°,ì „ì‹œ,ê±´ê°•ê²€ì§„,ì²´í—˜í–‰ì‚¬,ìº í˜ì¸ ë“± ë¹„ì˜ë¦¬, ê³µìµì„± ë¬¸í™”í–‰ì‚¬\\n- ìŠ¹ì¸ê°€ëŠ¥í–‰ì‚¬\\n- ê°œì¸ ë˜ëŠ” ë‹¨ì²´ì˜ ê±´ì „í•œ ì·¨ë¯¸í™œë™ í–‰ì‚¬\\n- ê³µìµì„± ë° ê³µê³µì„±ì´ í¬í•¨ëœ í™ë³´ ìº í˜ì¸\\n- ì§€ì—­ì£¼ë¯¼ê³¼ì˜ ìœ ëŒ€ë¥¼ ê°•í™” í•  ìˆ˜ ìˆëŠ” í–‰ì‚¬\\n- í•™êµì˜ ë™ì•„ë¦¬ í™œë™ ë“± ë¹„ìƒì—…ì ì¸ í–‰ì‚¬\\n- ê¸°íƒ€ ê³µì‚¬ì—ì„œ ìŠ¹ì¸í•œ í–‰ì‚¬\\n- ìŠ¹ì¸ ë¶ˆê°€ í–‰ì‚¬\\n- ì˜ë¦¬ë¥¼ ëª©ì ìœ¼ë¡œ í•˜ëŠ” ëª¨ë“  í–‰ì‚¬\\n- í™ë³´ìº í˜ì¸ì„ ë¹™ìí•œ íšŒì› ëª¨ì§‘ í–‰ì‚¬\\n- ì‚¬ê¸°ì—…ì˜ ì˜ì—…í–‰ìœ„ ë° í™ë³´í™œë™(íšŒì›ëª¨ì§‘, ë¬¼í’ˆì¦ì • ë“±)\\n- ëª¨ê¸ˆ ë° ìƒí–‰ìœ„ ë“± í™œë™(ë‹¨ ê³µì‚¬ì—ì„œ ìŠ¹ì¸í•œ í–‰ì‚¬ëŠ” ì œì™¸)\\n- ì´ìš©ê°ì—ê²Œ ë¶ˆí¸ ë° ë¶ˆì¾Œê°ì„ ì£¼ëŠ” í–‰ì‚¬(ì§€ë‚˜ì¹œ ì†ŒìŒë°œìƒ, ë‹¤ìˆ˜ì˜ ë¯¼ì›ë°œìƒ\\ní–‰ìœ„ ë“±)\\n- ì•ˆì „ì‚¬ê³ ì˜ ìš°ë ¤ê°€ ìˆëŠ” í–‰ì‚¬\\n- ì„ êµë¥¼ ëª©ì ìœ¼ë¡œ í•˜ëŠ” ì¢…êµ ê´€ë ¨ í–‰ì‚¬\\n- ì‚¬íšŒì  ì´ìŠˆê°€ ë˜ëŠ” ìº í˜ì¸ ê´€ë ¨ í–‰ì‚¬\\n- ì‹ ì²­ê¸°í•œ :\\n- í–‰ì‚¬ì¼ 10ì¼ì „ê¹Œì§€,1ê°œì›” ì´ë‚´ì˜ í–‰ì‚¬ë§Œ ì‹ ì²­ê°€ëŠ¥\\n- ìº í˜ì¸ì€ ì—­ë‹¹ 1ê°œì›”ë‚´ 5ì¼ ì´ˆê³¼ ë¶ˆê°€, ë™ì¼í–‰ì‚¬ ê²½ìš° 2ê°œì—­ê¹Œì§€ ì‹ ì²­ ê°€ëŠ¥\\n- ìŠ¹ì¸ì ˆì°¨\\n- ë¬¸í™”í–‰ì‚¬(í™ˆí˜ì´ì§€) ì‹ ì²­ â†’ ì í•©ì„± ì‹¬ì‚¬ â†’ ìŠ¹ì¸ ë° ë¶ˆê°€ â†’ í–‰ì‚¬ì§„í–‰\\n- ì„œë©´ì—­,ì—°ì‚°ì—­,ë¯¸ë‚¨ì—­ ê³µì—°í–‰ì‚¬ëŠ” ì ì • ì¤‘ë‹¨(ì‹¤ë‚´ ê³µì—° ì¬ê°œ ë³´ë¥˜)\\n- í–‰ì‚¬ì¼ì •ì€ í˜‘ì˜ì¡°ì • í›„ í™í˜ì´ì§€ì˜ ê³µì˜ì¼ì • ì•ˆë‚´ì— ê²Œì‹œ', metadata={'Header 1': 'STEPâ…  ì—­ë¬´ì¼ë°˜', 'Header 2': 'CHAPTER2 ê³ ê°ì„œë¹„ìŠ¤', 'Header 3': '9ê°• ì—­ì‚¬ ë‚´ ë¬¸í™”í–‰ì‚¬ ì‹ ì²­'}),\n",
              " Document(page_content='| ì‚¬ì§ | 05:38 | 05:36 | 00:02 | 00:14 |\\n| ë¯¸ë‚¨ | 05:36 | 05:37 | 00:00 | 00:16 |\\n| ë§Œë• | 05:32 | 05:42 | 23:56 | 00:21 |\\n| ë‚¨ì‚°ì • | 05:30 | 05:44 | 23:54 | 00:23 |\\n| ìˆ™ë“± | 05:28 | 05:46 | 23:52 | 00:25 |\\n| ë•ì²œ | 05:24 | 05:47 | 23:48 | 00:26 |\\n| êµ¬í¬ | 05:21 | 05:50 | 23:45 | 00:32 |\\n| ê°•ì„œêµ¬ì²­ | 05:19 | 05:52 | 23:43 | 00:34 |\\n| ì²´ìœ¡ê³µì› | 05:17 | 05:54 | 23:41 | 00:36 |\\n| ëŒ€ì € | 05:16 |  | 23:40 |  |\\n| ë¯¸ë‚¨ |  | 05:40 |  | 00:20 |\\n| ë™ë˜ | 05:31 | 05:42 | 00:06 | 00:22 |\\n| ìˆ˜ì•ˆ | 05:29 | 05:44 | 00:05 | 00:24 |\\n| ë‚™ë¯¼ | 05:27 | 05:45 | 00:03 | 00:25 |\\n| ì¶©ë ¬ì‚¬ | 05:25 | 05:47 | 00:01 | 00:27 |\\n| ëª…ì¥ | 05:23 | 05:49 | 00:00 | 00:28 |\\n| ì„œë™ | 05:21 | 05:51 | 23:57 | 00:31 |\\n| ê¸ˆì‚¬ | 05:19 | 05:53 | 23:55 | 00:32 |\\n| ë°˜ì—¬ | 05:17 | 05:54 | 23:54 | 00:34 |\\n| ì„ëŒ€ | 05:15 | 05:56 | 23:52 | 00:36 |\\n| ì˜ì‚°ëŒ€ | 05:12 | 05:59 | 23:49 | 00:38 |\\n| ìœ—ë°˜ì†¡ | 05:09 | 06:01 | 23:47 | 00:41 |\\n| ê³ ì´Œ | 05:07 | 06:03 | 23:45 | 00:42 |\\n| ì•ˆí‰ | 05:05 |  | 23:44 |  |', metadata={'Header 1': 'STEPâ…  ì—­ë¬´ì¼ë°˜', 'Header 2': 'CHAPTER1 ì—¬ê°ìš´ì†¡ê´€ë¦¬', 'Header 3': '5ê°• ì²«ì°¨ ë§‰ì°¨'})]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_db.max_marginal_relevance_search('í™”ì¥ì‹¤ì´ ì–´ë””ì¸ê°€ìš”')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent = initialize_agent(\n",
        "    tools=[get_train_schedule, get_estimated_time,\n",
        "           get_distance_type, ddg_search],\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_error=True,\n",
        "    verbose=True,\n",
        "    memory=memory,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"ì—­ì‚¬ ë‚´ í¸ì˜ì ì´ ìˆë‚˜ìš”?\",\n",
            "  \"chat_history\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"ì—­ì‚¬ ë‚´ í¸ì˜ì ì´ ìˆë‚˜ìš”?\",\n",
            "  \"chat_history\": \"\",\n",
            "  \"agent_scratchpad\": \"\",\n",
            "  \"stop\": [\n",
            "    \"\\nObservation:\",\n",
            "    \"\\n\\tObservation:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\nget_train_schedule: get_train_schedule(station_name: str = 'í•˜ë‹¨') -> str - Returns today's train schedule of the given station name.\\n    Output is formatted as CSV\\nget_estimated_time: get_estimated_time(from_station: str = 'í•˜ë‹¨') -> str - Returns all estimated time from from_station.\\nget_distance_type: get_distance_type(from_station: str = 'í•˜ë‹¨') -> str - Returns all distance type from_station\\nddg_search: ddg_search(query: str) -> str - When there is relavant tools, use this tool to search online and retrieve relavant information\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [get_train_schedule, get_estimated_time, get_distance_type, ddg_search]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: ì—­ì‚¬ ë‚´ í¸ì˜ì ì´ ìˆë‚˜ìš”?\\nThought:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] [1.57s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"I need to find out if there is a convenience store in the station.\\nAction: ddg_search\\nAction Input: \\\"ì—­ì‚¬ ë‚´ í¸ì˜ì \\\"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"example\": false,\n",
            "            \"content\": \"I need to find out if there is a convenience store in the station.\\nAction: ddg_search\\nAction Input: \\\"ì—­ì‚¬ ë‚´ í¸ì˜ì \\\"\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [1.57s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": \"I need to find out if there is a convenience store in the station.\\nAction: ddg_search\\nAction Input: \\\"ì—­ì‚¬ ë‚´ í¸ì˜ì \\\"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:ddg_search] Entering Tool run with input:\n",
            "\u001b[0m\"ì—­ì‚¬ ë‚´ í¸ì˜ì \"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sdh/anaconda3/envs/haa/lib/python3.10/site-packages/duckduckgo_search/compat.py:13: UserWarning: ddg is deprecated. Use DDGS().text() generator\n",
            "  warnings.warn(\"ddg is deprecated. Use DDGS().text() generator\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:ddg_search] [2.09s] Exiting Tool run with output:\n",
            "\u001b[0m\"ìš”ê¸ˆì€ ëª¨ë‘ ì‚¼ì²œì›ì…ë‹ˆë‹¤. ì–´ë¦°ì´ êµí†µì¹´ë“œë¥¼ ì‚´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—­ì‚¬ë‚´ì— í¸ì˜ì ì´ ìˆìŠµë‹ˆë‹¤.\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"ì—­ì‚¬ ë‚´ í¸ì˜ì ì´ ìˆë‚˜ìš”?\",\n",
            "  \"chat_history\": \"\",\n",
            "  \"agent_scratchpad\": \"I need to find out if there is a convenience store in the station.\\nAction: ddg_search\\nAction Input: \\\"ì—­ì‚¬ ë‚´ í¸ì˜ì \\\"\\nObservation: ìš”ê¸ˆì€ ëª¨ë‘ ì‚¼ì²œì›ì…ë‹ˆë‹¤. ì–´ë¦°ì´ êµí†µì¹´ë“œë¥¼ ì‚´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—­ì‚¬ë‚´ì— í¸ì˜ì ì´ ìˆìŠµë‹ˆë‹¤.\\nThought:\",\n",
            "  \"stop\": [\n",
            "    \"\\nObservation:\",\n",
            "    \"\\n\\tObservation:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: Answer the following questions as best you can. You have access to the following tools:\\n\\nget_train_schedule: get_train_schedule(station_name: str = 'í•˜ë‹¨') -> str - Returns today's train schedule of the given station name.\\n    Output is formatted as CSV\\nget_estimated_time: get_estimated_time(from_station: str = 'í•˜ë‹¨') -> str - Returns all estimated time from from_station.\\nget_distance_type: get_distance_type(from_station: str = 'í•˜ë‹¨') -> str - Returns all distance type from_station\\nddg_search: ddg_search(query: str) -> str - When there is relavant tools, use this tool to search online and retrieve relavant information\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [get_train_schedule, get_estimated_time, get_distance_type, ddg_search]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: ì—­ì‚¬ ë‚´ í¸ì˜ì ì´ ìˆë‚˜ìš”?\\nThought:I need to find out if there is a convenience store in the station.\\nAction: ddg_search\\nAction Input: \\\"ì—­ì‚¬ ë‚´ í¸ì˜ì \\\"\\nObservation: ìš”ê¸ˆì€ ëª¨ë‘ ì‚¼ì²œì›ì…ë‹ˆë‹¤. ì–´ë¦°ì´ êµí†µì¹´ë“œë¥¼ ì‚´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—­ì‚¬ë‚´ì— í¸ì˜ì ì´ ìˆìŠµë‹ˆë‹¤.\\nThought:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] [1.36s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"I found information that there is a convenience store in the station.\\nFinal Answer: Yes, there is a convenience store in the station.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"example\": false,\n",
            "            \"content\": \"I found information that there is a convenience store in the station.\\nFinal Answer: Yes, there is a convenience store in the station.\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain] [1.37s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": \"I found information that there is a convenience store in the station.\\nFinal Answer: Yes, there is a convenience store in the station.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [5.03s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Yes, there is a convenience store in the station.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "result = agent.run('ì—­ì‚¬ ë‚´ í¸ì˜ì ì´ ìˆë‚˜ìš”?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yes, there is a convenience store in the station.\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "haa",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
