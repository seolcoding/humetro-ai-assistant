# code from https://python.langchain.com/docs/integrations/callbacks/streamlit?ref=blog.langchain.dev#installation-and-setup
import openai
import os

from llm_tools.GoogleRoutes import GoogleRouteTool
from llm_tools.HumetroFareTool import HumetroFareTool
from llm_tools.HumetroWebSearchTool import HumetroWebSearchTool
from mongo_db import save_to_mongo

import langchain
langchain.debug= True

from langchain.chat_models import ChatOpenAI
from langchain.prompts  import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferMemory
from langchain.callbacks import StreamlitCallbackHandler
from langchain.agents import  OpenAIFunctionsAgent, AgentExecutor, OpenAIMultiFunctionsAgent
from langchain.memory.chat_message_histories import StreamlitChatMessageHistory
from dotenv import load_dotenv, find_dotenv

import streamlit as st
from llm_tools.prompts import humetro_system_prompt

from capturing_callback_handler import playback_callbacks
from clear_results import with_clear_container
from streamlit_agent import haa_executor

_ = load_dotenv(find_dotenv())  # read local .env file
openai.api_key = os.environ['OPENAI_API_KEY']

st.set_page_config(page_title="Humetro-AI-Assistant",
                   page_icon="ğŸ¤–")

if 'langchain_messages' not in st.session_state:
    st.session_state.langchain_messages = []

chat_history = StreamlitChatMessageHistory(key="langchain_messages")
memory = ConversationBufferMemory(memory_key='chat_history', chat_memory=chat_history)


if len(chat_history.messages)  == 0:
    chat_history.add_ai_message("ì•ˆë…•í•˜ì„¸ìš” í•˜ë‹¨ì—­ì˜ ì¸ê³µì§€ëŠ¥ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ê²ƒì´ ìˆìœ¼ì‹œë©´ ë¬¼ì–´ë³´ì„¸ìš”!")

st.write("# ğŸš‡ Humetro AI Assistant")
st.write("### ğŸ¤– ì¸ê³µì§€ëŠ¥ ì–´ì‹œìŠ¤í„´íŠ¸ì—ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”!")
st.write('**ì´ì „ ëŒ€í™”ëª©ë¡ í™•ì¸í•˜ê¸°(ì•„ë˜ í´ë¦­)**')
st.json(st.session_state, expanded=False)
st.write(chat_history.messages)

output_container = st.empty()
answer_container = st.empty()

output_container = output_container.container()
# ìµœì´ˆ ì¸ì‚¿ë§ì´ ì¶œë ¥ë˜ë„ë¡ í•œë‹¤.
if len(st.session_state.langchain_messages) == 1:
    output_container.chat_message(chat_history.messages[0].type).write(chat_history.messages[0].content)

# ì¤‘ë³µì„ ë°°ì œí•˜ê¸° ìœ„í•´ ë§ˆì§€ë§‰ ë‘ê°œì˜ ë©”ì‹œì§€ë¥¼ ì œì™¸í•œ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•œë‹¤.
for msg in st.session_state.langchain_messages[:-2]:
    output_container.chat_message(msg.type).write(msg.content)

if user_input := st.chat_input('ì´ê³³ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.'):
    output_container.chat_message("user").write(user_input)

    answer_container = output_container.chat_message("assistant")
    st_callback = StreamlitCallbackHandler(answer_container)

    haa_executor.memory = memory
    answer = haa_executor.run({"input":user_input}, callbacks=[st_callback])
    answer_container.write(answer)

    # ë©”ì‹œì§€ë¥¼ ë©”ì‹œì§€ë¥¼ ë³´ê´€í•˜ëŠ” ì„¸ì…˜ì— ì €ì¥í•œë‹¤.
    chat_history.add_user_message(user_input)
    chat_history.add_ai_message(answer)
    save_to_mongo(user_input, answer)